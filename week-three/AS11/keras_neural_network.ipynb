{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tf-gpu",
   "display_name": "TensorFlow-GPU-2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "D:\\Anaconda_Server\n"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'Hello from TensorFlow 2.1.0', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print( tf.constant( 'Hello from TensorFlow ' + tf.__version__ ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(r\"D:\\GitRepos\\course-machine-learning\\week-three\\AS11\\mnist_train.csv\", header=None)\n",
    "test = pd.read_csv(r\"D:\\GitRepos\\course-machine-learning\\week-three\\AS11\\mnist_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n0    5    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n2    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n3    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n4    9    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n\n   779  780  781  782  783  784  \n0    0    0    0    0    0    0  \n1    0    0    0    0    0    0  \n2    0    0    0    0    0    0  \n3    0    0    0    0    0    0  \n4    0    0    0    0    0    0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n0    7    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n1    2    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n2    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n4    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n\n   779  780  781  782  783  784  \n0    0    0    0    0    0    0  \n1    0    0    0    0    0    0  \n2    0    0    0    0    0    0  \n3    0    0    0    0    0    0  \n4    0    0    0    0    0    0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                0        1        2        3        4        5        6    \\\ncount  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \nmean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n           7        8        9    ...           775           776  \\\ncount  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \nmean       0.0      0.0      0.0  ...      0.200433      0.088867   \nstd        0.0      0.0      0.0  ...      6.042472      3.956189   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    254.000000    254.000000   \n\n                777           778           779         780      781      782  \\\ncount  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \nmean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \nstd        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \nmin        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \nmax      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n\n           783      784  \ncount  60000.0  60000.0  \nmean       0.0      0.0  \nstd        0.0      0.0  \nmin        0.0      0.0  \n25%        0.0      0.0  \n50%        0.0      0.0  \n75%        0.0      0.0  \nmax        0.0      0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>60000.000000</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>...</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.0000</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n      <td>60000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.453933</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.200433</td>\n      <td>0.088867</td>\n      <td>0.045633</td>\n      <td>0.019283</td>\n      <td>0.015117</td>\n      <td>0.0020</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.889270</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>6.042472</td>\n      <td>3.956189</td>\n      <td>2.839845</td>\n      <td>1.686770</td>\n      <td>1.678283</td>\n      <td>0.3466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>253.000000</td>\n      <td>253.000000</td>\n      <td>254.000000</td>\n      <td>62.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                0        1        2        3        4        5        6    \\\ncount  10000.000000  10000.0  10000.0  10000.0  10000.0  10000.0  10000.0   \nmean       4.443400      0.0      0.0      0.0      0.0      0.0      0.0   \nstd        2.895865      0.0      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \nmax        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n\n           7        8        9    ...           775           776  \\\ncount  10000.0  10000.0  10000.0  ...  10000.000000  10000.000000   \nmean       0.0      0.0      0.0  ...      0.179300      0.163600   \nstd        0.0      0.0      0.0  ...      5.674149      5.736072   \nmin        0.0      0.0      0.0  ...      0.000000      0.000000   \n25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n75%        0.0      0.0      0.0  ...      0.000000      0.000000   \nmax        0.0      0.0      0.0  ...    253.000000    253.000000   \n\n                777         778      779      780      781      782      783  \\\ncount  10000.000000  10000.0000  10000.0  10000.0  10000.0  10000.0  10000.0   \nmean       0.052600      0.0006      0.0      0.0      0.0      0.0      0.0   \nstd        2.420004      0.0600      0.0      0.0      0.0      0.0      0.0   \nmin        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n25%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n50%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \n75%        0.000000      0.0000      0.0      0.0      0.0      0.0      0.0   \nmax      156.000000      6.0000      0.0      0.0      0.0      0.0      0.0   \n\n           784  \ncount  10000.0  \nmean       0.0  \nstd        0.0  \nmin        0.0  \n25%        0.0  \n50%        0.0  \n75%        0.0  \nmax        0.0  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>...</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.0000</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n      <td>10000.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.443400</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.179300</td>\n      <td>0.163600</td>\n      <td>0.052600</td>\n      <td>0.0006</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.895865</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5.674149</td>\n      <td>5.736072</td>\n      <td>2.420004</td>\n      <td>0.0600</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>253.000000</td>\n      <td>253.000000</td>\n      <td>156.000000</td>\n      <td>6.0000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 60000 entries, 0 to 59999\nColumns: 785 entries, 0 to 784\ndtypes: int64(785)\nmemory usage: 359.3 MB\n"
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1, 785):\n",
    "    train[i] = train[i].apply(lambda x: (x * (0.99/255)) + 0.01)\n",
    "    test[i] = test[i].apply(lambda x: (x * (0.99/255)) + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                0         1         2         3         4         5    \\\ncount  60000.000000  60000.00  60000.00  60000.00  60000.00  60000.00   \nmean       4.453933      0.01      0.01      0.01      0.01      0.01   \nstd        2.889270      0.00      0.00      0.00      0.00      0.00   \nmin        0.000000      0.01      0.01      0.01      0.01      0.01   \n25%        2.000000      0.01      0.01      0.01      0.01      0.01   \n50%        4.000000      0.01      0.01      0.01      0.01      0.01   \n75%        7.000000      0.01      0.01      0.01      0.01      0.01   \nmax        9.000000      0.01      0.01      0.01      0.01      0.01   \n\n            6         7         8         9    ...           775  \\\ncount  60000.00  60000.00  60000.00  60000.00  ...  60000.000000   \nmean       0.01      0.01      0.01      0.01  ...      0.010778   \nstd        0.00      0.00      0.00      0.00  ...      0.023459   \nmin        0.01      0.01      0.01      0.01  ...      0.010000   \n25%        0.01      0.01      0.01      0.01  ...      0.010000   \n50%        0.01      0.01      0.01      0.01  ...      0.010000   \n75%        0.01      0.01      0.01      0.01  ...      0.010000   \nmax        0.01      0.01      0.01      0.01  ...      0.996118   \n\n                776           777           778           779           780  \\\ncount  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \nmean       0.010345      0.010177      0.010075      0.010059      0.010008   \nstd        0.015359      0.011025      0.006549      0.006516      0.001346   \nmin        0.010000      0.010000      0.010000      0.010000      0.010000   \n25%        0.010000      0.010000      0.010000      0.010000      0.010000   \n50%        0.010000      0.010000      0.010000      0.010000      0.010000   \n75%        0.010000      0.010000      0.010000      0.010000      0.010000   \nmax        0.996118      0.992235      0.992235      0.996118      0.250706   \n\n            781       782       783       784  \ncount  60000.00  60000.00  60000.00  60000.00  \nmean       0.01      0.01      0.01      0.01  \nstd        0.00      0.00      0.00      0.00  \nmin        0.01      0.01      0.01      0.01  \n25%        0.01      0.01      0.01      0.01  \n50%        0.01      0.01      0.01      0.01  \n75%        0.01      0.01      0.01      0.01  \nmax        0.01      0.01      0.01      0.01  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>60000.000000</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>...</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.000000</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n      <td>60000.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.453933</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010778</td>\n      <td>0.010345</td>\n      <td>0.010177</td>\n      <td>0.010075</td>\n      <td>0.010059</td>\n      <td>0.010008</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.889270</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.023459</td>\n      <td>0.015359</td>\n      <td>0.011025</td>\n      <td>0.006549</td>\n      <td>0.006516</td>\n      <td>0.001346</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.996118</td>\n      <td>0.996118</td>\n      <td>0.992235</td>\n      <td>0.992235</td>\n      <td>0.996118</td>\n      <td>0.250706</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                0         1         2         3         4         5    \\\ncount  10000.000000  10000.00  10000.00  10000.00  10000.00  10000.00   \nmean       4.443400      0.01      0.01      0.01      0.01      0.01   \nstd        2.895865      0.00      0.00      0.00      0.00      0.00   \nmin        0.000000      0.01      0.01      0.01      0.01      0.01   \n25%        2.000000      0.01      0.01      0.01      0.01      0.01   \n50%        4.000000      0.01      0.01      0.01      0.01      0.01   \n75%        7.000000      0.01      0.01      0.01      0.01      0.01   \nmax        9.000000      0.01      0.01      0.01      0.01      0.01   \n\n            6         7         8         9    ...           775  \\\ncount  10000.00  10000.00  10000.00  10000.00  ...  10000.000000   \nmean       0.01      0.01      0.01      0.01  ...      0.010696   \nstd        0.00      0.00      0.00      0.00  ...      0.022029   \nmin        0.01      0.01      0.01      0.01  ...      0.010000   \n25%        0.01      0.01      0.01      0.01  ...      0.010000   \n50%        0.01      0.01      0.01      0.01  ...      0.010000   \n75%        0.01      0.01      0.01      0.01  ...      0.010000   \nmax        0.01      0.01      0.01      0.01  ...      0.992235   \n\n                776           777           778       779       780       781  \\\ncount  10000.000000  10000.000000  10000.000000  10000.00  10000.00  10000.00   \nmean       0.010635      0.010204      0.010002      0.01      0.01      0.01   \nstd        0.022269      0.009395      0.000233      0.00      0.00      0.00   \nmin        0.010000      0.010000      0.010000      0.01      0.01      0.01   \n25%        0.010000      0.010000      0.010000      0.01      0.01      0.01   \n50%        0.010000      0.010000      0.010000      0.01      0.01      0.01   \n75%        0.010000      0.010000      0.010000      0.01      0.01      0.01   \nmax        0.992235      0.615647      0.033294      0.01      0.01      0.01   \n\n            782       783       784  \ncount  10000.00  10000.00  10000.00  \nmean       0.01      0.01      0.01  \nstd        0.00      0.00      0.00  \nmin        0.01      0.01      0.01  \n25%        0.01      0.01      0.01  \n50%        0.01      0.01      0.01  \n75%        0.01      0.01      0.01  \nmax        0.01      0.01      0.01  \n\n[8 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>775</th>\n      <th>776</th>\n      <th>777</th>\n      <th>778</th>\n      <th>779</th>\n      <th>780</th>\n      <th>781</th>\n      <th>782</th>\n      <th>783</th>\n      <th>784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000000</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>...</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n      <td>10000.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.443400</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010696</td>\n      <td>0.010635</td>\n      <td>0.010204</td>\n      <td>0.010002</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.895865</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.022029</td>\n      <td>0.022269</td>\n      <td>0.009395</td>\n      <td>0.000233</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.010000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.000000</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>...</td>\n      <td>0.992235</td>\n      <td>0.992235</td>\n      <td>0.615647</td>\n      <td>0.033294</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cols = [i for i in range(1, 785)]\n",
    "\n",
    "ohe = OneHotEncoder(categories=\"auto\", sparse=False, dtype=np.int16)\n",
    "\n",
    "train_y = ohe.fit_transform(train[0].to_numpy().reshape(-1, 1))\n",
    "# transformed = pd.DataFrame(transformed, columns=ohe.categories_[0]) \n",
    "# df_train = pd.concat([transformed, train[cols]], axis=1)\n",
    "train_X = train.drop([0], axis=1).to_numpy()\n",
    "\n",
    "test_y = ohe.fit_transform(test[0].to_numpy().reshape(-1, 1))\n",
    "# transformed = pd.DataFrame(transformed, columns=ohe.categories_[0]) \n",
    "# df_test = pd.concat([transformed, test[cols]], axis=1)\n",
    "test_X = test.drop([0], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(train_x, train_y, config):\n",
    "    n_input = config[0]\n",
    "    n_output = config[1]\n",
    "    n_nodes = config[2]\n",
    "    epoch = config[3]\n",
    "    batch = config[4]\n",
    "    # Define and Compile\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_nodes, input_dim=n_input, activation='relu'))\n",
    "    model.add(Dense(n_output, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(train_x, train_y, epochs=epoch, batch_size=batch)\n",
    "    return model\n",
    "\n",
    "# predict with the fit model\n",
    "def model_predict(model, testdata):\n",
    "    Prediction = model.predict(testdata, verbose=0)\n",
    "    return Prediction\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10\n[[784, 10, 5, 75, 250], [784, 10, 10, 75, 250], [784, 10, 15, 75, 250], [784, 10, 20, 75, 250], [784, 10, 25, 75, 250], [784, 10, 30, 75, 250], [784, 10, 35, 75, 250], [784, 10, 40, 75, 250], [784, 10, 45, 75, 250], [784, 10, 50, 75, 250]]\n"
    }
   ],
   "source": [
    "inputs = 784 # Input features\n",
    "outputs = 10 # Output features\n",
    "\n",
    "# Find best model:\n",
    "nodes = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "# nodes = [5, 45, 50]\n",
    "configs = []\n",
    "for n in nodes:\n",
    "    config_ = [inputs, outputs, n, 75, 250]\n",
    "    configs.append(config_)\n",
    "\n",
    "print(len(configs))\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===] - 1s 15us/step - loss: 0.0112 - accuracy: 0.9966\nEpoch 40/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0109 - accuracy: 0.9967\nEpoch 41/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0106 - accuracy: 0.9967\nEpoch 42/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0103 - accuracy: 0.9969\nEpoch 43/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0101 - accuracy: 0.9969\nEpoch 44/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0099 - accuracy: 0.9970\nEpoch 45/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0096 - accuracy: 0.9971\nEpoch 46/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0093 - accuracy: 0.9972\nEpoch 47/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0091 - accuracy: 0.9973\nEpoch 48/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0089 - accuracy: 0.9973\nEpoch 49/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0087 - accuracy: 0.9975\nEpoch 50/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0085 - accuracy: 0.9975\nEpoch 51/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0083 - accuracy: 0.9976\nEpoch 52/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0081 - accuracy: 0.9977\nEpoch 53/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0079 - accuracy: 0.9977\nEpoch 54/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0077 - accuracy: 0.9978\nEpoch 55/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0076 - accuracy: 0.9979\nEpoch 56/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0074 - accuracy: 0.9979\nEpoch 57/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0073 - accuracy: 0.9979\nEpoch 58/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0071 - accuracy: 0.9981\nEpoch 59/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0069 - accuracy: 0.9981\nEpoch 60/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0068 - accuracy: 0.9981\nEpoch 61/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0067 - accuracy: 0.9982\nEpoch 62/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0065 - accuracy: 0.9982\nEpoch 63/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0064 - accuracy: 0.9983\nEpoch 64/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0061 - accuracy: 0.9984\nEpoch 65/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0060 - accuracy: 0.9985\nEpoch 66/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0059 - accuracy: 0.9984\nEpoch 67/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0058 - accuracy: 0.9985\nEpoch 68/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0057 - accuracy: 0.9985\nEpoch 69/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0055 - accuracy: 0.9986\nEpoch 70/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0054 - accuracy: 0.9986\nEpoch 71/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0053 - accuracy: 0.9987\nEpoch 72/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0051 - accuracy: 0.9987\nEpoch 73/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0050 - accuracy: 0.9987\nEpoch 74/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0049 - accuracy: 0.9988\nEpoch 75/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0048 - accuracy: 0.9988\nScore for config 10 fold 3: loss=0.02988259855871244; accuracy=99.22249913215637%\nEpoch 1/75\n48000/48000 [==============================] - 1s 16us/step - loss: 0.1896 - accuracy: 0.9329\nEpoch 2/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0849 - accuracy: 0.9735\nEpoch 3/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0692 - accuracy: 0.9784\nEpoch 4/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0617 - accuracy: 0.9807\nEpoch 5/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0556 - accuracy: 0.9825\nEpoch 6/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0496 - accuracy: 0.9846\nEpoch 7/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0447 - accuracy: 0.9861\nEpoch 8/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0412 - accuracy: 0.9872\nEpoch 9/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0385 - accuracy: 0.9881\nEpoch 10/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0362 - accuracy: 0.9888\nEpoch 11/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0342 - accuracy: 0.9895\nEpoch 12/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0323 - accuracy: 0.9899\nEpoch 13/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0305 - accuracy: 0.9906\nEpoch 14/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0290 - accuracy: 0.9910\nEpoch 15/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0276 - accuracy: 0.9913\nEpoch 16/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0264 - accuracy: 0.9918\nEpoch 17/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0253 - accuracy: 0.9921\nEpoch 18/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0245 - accuracy: 0.9924\nEpoch 19/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0235 - accuracy: 0.9927\nEpoch 20/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0227 - accuracy: 0.9930\nEpoch 21/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0218 - accuracy: 0.9933\nEpoch 22/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0210 - accuracy: 0.9936\nEpoch 23/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0203 - accuracy: 0.9937\nEpoch 24/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0196 - accuracy: 0.9940\nEpoch 25/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0191 - accuracy: 0.9940\nEpoch 26/75\n48000/48000 [==============================] - 1s 15us/step - loss: 0.0185 - accuracy: 0.9943\nEpoch 27/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0179 - accuracy: 0.9944\nEpoch 28/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0174 - accuracy: 0.9947\nEpoch 29/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0169 - accuracy: 0.9948\nEpoch 30/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0164 - accuracy: 0.9950\nEpoch 31/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0160 - accuracy: 0.9950\nEpoch 32/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0156 - accuracy: 0.9952\nEpoch 33/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0151 - accuracy: 0.9953\nEpoch 34/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0148 - accuracy: 0.9954\nEpoch 35/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0144 - accuracy: 0.9955\nEpoch 36/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0140 - accuracy: 0.9957\nEpoch 37/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0137 - accuracy: 0.9958\nEpoch 38/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0134 - accuracy: 0.9959\nEpoch 39/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0131 - accuracy: 0.9960\nEpoch 40/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0127 - accuracy: 0.9962\nEpoch 41/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0125 - accuracy: 0.9961\nEpoch 42/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0122 - accuracy: 0.9963\nEpoch 43/75\n48000/48000 [==============================] - 1s 15us/step - loss: 0.0120 - accuracy: 0.9963\nEpoch 44/75\n48000/48000 [==============================] - 1s 15us/step - loss: 0.0117 - accuracy: 0.9964\nEpoch 45/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0114 - accuracy: 0.9966\nEpoch 46/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0112 - accuracy: 0.9966\nEpoch 47/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0110 - accuracy: 0.9967\nEpoch 48/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0108 - accuracy: 0.9967\nEpoch 49/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0106 - accuracy: 0.9967\nEpoch 50/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0104 - accuracy: 0.9968\nEpoch 51/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0101 - accuracy: 0.9970\nEpoch 52/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0100 - accuracy: 0.9971\nEpoch 53/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0097 - accuracy: 0.9971\nEpoch 54/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0096 - accuracy: 0.9972\nEpoch 55/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0093 - accuracy: 0.9972\nEpoch 56/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0092 - accuracy: 0.9972\nEpoch 57/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0090 - accuracy: 0.9974\nEpoch 58/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0088 - accuracy: 0.9974\nEpoch 59/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0086 - accuracy: 0.9975\nEpoch 60/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0084 - accuracy: 0.9975\nEpoch 61/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0083 - accuracy: 0.9976\nEpoch 62/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0081 - accuracy: 0.9977\nEpoch 63/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0079 - accuracy: 0.9977\nEpoch 64/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0078 - accuracy: 0.9978\nEpoch 65/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0076 - accuracy: 0.9978\nEpoch 66/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0074 - accuracy: 0.9979\nEpoch 67/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0073 - accuracy: 0.9980\nEpoch 68/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0072 - accuracy: 0.9980\nEpoch 69/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0071 - accuracy: 0.9980\nEpoch 70/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0068 - accuracy: 0.9981\nEpoch 71/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0068 - accuracy: 0.9981\nEpoch 72/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0066 - accuracy: 0.9981\nEpoch 73/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0065 - accuracy: 0.9982\nEpoch 74/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0064 - accuracy: 0.9983\nEpoch 75/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0062 - accuracy: 0.9983\nScore for config 10 fold 4: loss=0.028010003274927538; accuracy=99.22749996185303%\nEpoch 1/75\n48000/48000 [==============================] - 1s 16us/step - loss: 0.1847 - accuracy: 0.9354\nEpoch 2/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0813 - accuracy: 0.9749\nEpoch 3/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0651 - accuracy: 0.9799\nEpoch 4/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0564 - accuracy: 0.9824\nEpoch 5/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0500 - accuracy: 0.9843\nEpoch 6/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0453 - accuracy: 0.9858\nEpoch 7/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0416 - accuracy: 0.9871\nEpoch 8/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0383 - accuracy: 0.9882\nEpoch 9/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0356 - accuracy: 0.9890\nEpoch 10/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0334 - accuracy: 0.9896\nEpoch 11/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0315 - accuracy: 0.9904\nEpoch 12/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0298 - accuracy: 0.9908\nEpoch 13/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0284 - accuracy: 0.9913\nEpoch 14/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0271 - accuracy: 0.9916\nEpoch 15/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0260 - accuracy: 0.9920\nEpoch 16/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0250 - accuracy: 0.9922\nEpoch 17/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0241 - accuracy: 0.9925\nEpoch 18/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0233 - accuracy: 0.9928\nEpoch 19/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0225 - accuracy: 0.9930\nEpoch 20/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0217 - accuracy: 0.9932\nEpoch 21/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0209 - accuracy: 0.9934\nEpoch 22/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0203 - accuracy: 0.9938\nEpoch 23/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0196 - accuracy: 0.9939\nEpoch 24/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0190 - accuracy: 0.9941\nEpoch 25/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0184 - accuracy: 0.9943\nEpoch 26/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0178 - accuracy: 0.9946\nEpoch 27/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0173 - accuracy: 0.9947\nEpoch 28/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0167 - accuracy: 0.9949\nEpoch 29/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0163 - accuracy: 0.9950\nEpoch 30/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0157 - accuracy: 0.9952\nEpoch 31/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0153 - accuracy: 0.9953\nEpoch 32/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0148 - accuracy: 0.9954\nEpoch 33/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0143 - accuracy: 0.9956\nEpoch 34/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0139 - accuracy: 0.9957\nEpoch 35/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0134 - accuracy: 0.9959\nEpoch 36/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0131 - accuracy: 0.9960\nEpoch 37/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0127 - accuracy: 0.9960\nEpoch 38/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0124 - accuracy: 0.9962\nEpoch 39/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0120 - accuracy: 0.9963\nEpoch 40/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0117 - accuracy: 0.9964\nEpoch 41/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0115 - accuracy: 0.9965\nEpoch 42/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0111 - accuracy: 0.9966\nEpoch 43/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0108 - accuracy: 0.9968\nEpoch 44/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0105 - accuracy: 0.9968\nEpoch 45/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0102 - accuracy: 0.9970\nEpoch 46/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0100 - accuracy: 0.9970\nEpoch 47/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0097 - accuracy: 0.9971\nEpoch 48/75\n48000/48000 [==============================] - 1s 15us/step - loss: 0.0095 - accuracy: 0.9972\nEpoch 49/75\n48000/48000 [==============================] - 1s 15us/step - loss: 0.0092 - accuracy: 0.9974\nEpoch 50/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0090 - accuracy: 0.9974\nEpoch 51/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0087 - accuracy: 0.9975\nEpoch 52/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0084 - accuracy: 0.9976\nEpoch 53/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0082 - accuracy: 0.9977\nEpoch 54/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0080 - accuracy: 0.9978\nEpoch 55/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0078 - accuracy: 0.9978\nEpoch 56/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0076 - accuracy: 0.9979\nEpoch 57/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0074 - accuracy: 0.9980\nEpoch 58/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0072 - accuracy: 0.9979\nEpoch 59/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0070 - accuracy: 0.9981\nEpoch 60/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0070 - accuracy: 0.9981\nEpoch 61/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0066 - accuracy: 0.9982\nEpoch 62/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0065 - accuracy: 0.9983\nEpoch 63/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0063 - accuracy: 0.9983\nEpoch 64/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0062 - accuracy: 0.9984\nEpoch 65/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0061 - accuracy: 0.9983\nEpoch 66/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0059 - accuracy: 0.9985\nEpoch 67/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0058 - accuracy: 0.9985\nEpoch 68/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0056 - accuracy: 0.9986\nEpoch 69/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0054 - accuracy: 0.9986\nEpoch 70/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0053 - accuracy: 0.9986\nEpoch 71/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0051 - accuracy: 0.9987\nEpoch 72/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0051 - accuracy: 0.9987\nEpoch 73/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0049 - accuracy: 0.9988\nEpoch 74/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0048 - accuracy: 0.9988\nEpoch 75/75\n48000/48000 [==============================] - 1s 14us/step - loss: 0.0047 - accuracy: 0.9989\nScore for config 10 fold 5: loss=0.027046886275988072; accuracy=99.24419522285461%\n"
    }
   ],
   "source": [
    "# MY WAY USING KFOLD\n",
    "loss_per_config = []\n",
    "accuracy_per_config = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=111)\n",
    "\n",
    "config_nr = 0\n",
    "for conf in configs:\n",
    "    config_nr += 1\n",
    "    fold_nr = 0\n",
    "\n",
    "    loss_per_fold = []\n",
    "    accuracy_per_fold = []\n",
    "    for fold_train, fold_test in kf.split(train_X, train_y):\n",
    "        fold_nr += 1\n",
    "        neural_network_model = model_fit(train_X[fold_train], train_y[fold_train], conf)\n",
    "        scores = neural_network_model.evaluate(train_X[fold_test], train_y[fold_test], verbose=0)\n",
    "        print(f\"Score for config {config_nr} fold {fold_nr}: {neural_network_model.metrics_names[0]}={scores[0]}; {neural_network_model.metrics_names[1]}={scores[1]*100}%\")\n",
    "\n",
    "        loss_per_fold.append(scores[0])\n",
    "        accuracy_per_fold.append(scores[1]*100)\n",
    "\n",
    "    loss_per_config.append(loss_per_fold)\n",
    "    accuracy_per_config.append(accuracy_per_fold)\n",
    "    with open(\"D:\\GitRepos\\course-machine-learning\\week-three\\AS11\\scores.txt\", \"a\") as text_file:\n",
    "        text_file.write(f\"Config: {config_nr}: {str(conf)}\\n\")\n",
    "        text_file.write(\"Loss per fold: \")\n",
    "        text_file.write(str(loss_per_fold))\n",
    "        text_file.write(\"\\n\")\n",
    "        text_file.write(\"Acc per fold: \")\n",
    "        text_file.write(str(accuracy_per_fold))\n",
    "        text_file.write(\"\\n\")\n",
    "        text_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Score per config: \n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 1. Nodes:5\nAverage scores for all folds:\n> Loss: 0.11795923417806624\n> Accuracy: 96.12768769264221 (+- 1.0288292721550178)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 2. Nodes:10\nAverage scores for all folds:\n> Loss: 0.057557183845837925\n> Accuracy: 98.25085520744324 (+- 0.13928728558584907)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 3. Nodes:15\nAverage scores for all folds:\n> Loss: 0.045339991742124164\n> Accuracy: 98.61850142478943 (+- 0.04437495358204493)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 4. Nodes:20\nAverage scores for all folds:\n> Loss: 0.036986177019930136\n> Accuracy: 98.86383414268494 (+- 0.08260689180277879)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 5. Nodes:25\nAverage scores for all folds:\n> Loss: 0.0344866450241146\n> Accuracy: 98.96667122840881 (+- 0.037503874986217406)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 6. Nodes:30\nAverage scores for all folds:\n> Loss: 0.032131633525869494\n> Accuracy: 99.04534101486206 (+- 0.06053659580271297)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 7. Nodes:35\nAverage scores for all folds:\n> Loss: 0.029771203285952407\n> Accuracy: 99.1346287727356 (+- 0.02393586621045003)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 8. Nodes:40\nAverage scores for all folds:\n> Loss: 0.029316277698924142\n> Accuracy: 99.16417121887207 (+- 0.02852861176976193)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 9. Nodes:45\nAverage scores for all folds:\n> Loss: 0.028153203483026783\n> Accuracy: 99.20999050140381 (+- 0.03826972567706596)\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nScore for config 10. Nodes:50\nAverage scores for all folds:\n> Loss: 0.028458737153598722\n> Accuracy: 99.21750664710999 (+- 0.01846861651700187)\n\n"
    }
   ],
   "source": [
    "print(\"Score per config: \")\n",
    "for j in range(0, len(accuracy_per_config)):\n",
    "    print('^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^')\n",
    "    print(f'Score for config {j+1}. Nodes:{configs[j][2]}')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Loss: {np.mean(loss_per_config[j])}')\n",
    "    print(f'> Accuracy: {np.mean(accuracy_per_config[j])} (+- {np.std(accuracy_per_config[j])})')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# model_nrs = [1, 9, 10]\n",
    "# itera = -1\n",
    "# for config in configs:\n",
    "#     itera += 1\n",
    "#     model_name = \"\\ModelV2_\" + str(model_nrs[itera])\n",
    "#     fullpath = r\"D:\\GitRepos\\course-machine-learning\\week-three\\AS11\\saved_models\"\n",
    "#     fullpath += model_name\n",
    "\n",
    "#     neural_network = model_fit(train_X, train_y, config)\n",
    "\n",
    "#     prediction = model_predict(neural_network, test_X)\n",
    "\n",
    "#     PredClass = list()\n",
    "#     ActualClass = list()\n",
    "#     for row in range(len(test_y)):\n",
    "#         index_maxscore1 = max(range(len(test_y[row])), key=test_y[row].__getitem__)\n",
    "#         ActualClass.append(index_maxscore1)\n",
    "#         index_maxscore2 = max(range(len(prediction[row])), key=prediction[row].__getitem__)\n",
    "#         PredClass.append(index_maxscore2)\n",
    "#         # print('Expected=%d, Got=%d' % (index_maxscore1, index_maxscore2))\n",
    "\n",
    "\n",
    "#     accuracy = accuracy_metric(PredClass, ActualClass)\n",
    "#     scores.append(accuracy)\n",
    "\n",
    "#     model_as_json = neural_network.to_json()\n",
    "#     with open(fullpath+\".json\", \"w\") as json_file:\n",
    "#         json_file.write(model_as_json)\n",
    "#     neural_network.save_weights(fullpath+\".h5\")\n",
    "#     print(\"Model saved\")\n",
    "\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# prediction = model_predict(neural_network, test_X)\n",
    "\n",
    "# PredClass = list()\n",
    "# ActualClass = list()\n",
    "# for row in range(len(test_y)):\n",
    "#     index_maxscore1 = max(range(len(test_y[row])), key=test_y[row].__getitem__)\n",
    "#     ActualClass.append(index_maxscore1)\n",
    "#     index_maxscore2 = max(range(len(prediction[row])), key=prediction[row].__getitem__)\n",
    "#     PredClass.append(index_maxscore2)\n",
    "#     # print('Expected=%d, Got=%d' % (index_maxscore1, index_maxscore2))\n",
    "\n",
    "\n",
    "# accuracy = accuracy_metric(PredClass, ActualClass)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING MODELS EXAMPLE\n",
    "\n",
    "json_file = open(PATH, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(WEIGHTS_PATH)\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1, 4, 5]\n"
    }
   ],
   "source": [
    "adadad = [1, 4, 5]\n",
    "print(str(adadad))"
   ]
  }
 ]
}